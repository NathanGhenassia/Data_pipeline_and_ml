import streamlit as st
import os
import joblib
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import requests
from io import StringIO
from sklearn.metrics import accuracy_score, confusion_matrix
from data_pipeline import DataPipeline

# Configuraci√≥n de la p√°gina en Streamlit
st.set_page_config(
    page_title="Pipeline y Modelo de IA",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos personalizados con hover en botones
st.markdown(
    """
    <style>
    .main-title {
        text-align: center;
        font-size: 36px;
        font-weight: bold;
        color: #4CAF50;
    }
    .stButton > button {
        background-color: #4CAF50;
        color: white;
        border-radius: 8px;
        font-size: 16px;
        padding: 10px;
    }
    .stButton > button:hover {
        background-color: #45a049 !important;
        transform: scale(1.05);
        transition: 0.3s;
    }
    .stDataFrame {
        border-radius: 10px;
        box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Barra lateral
st.sidebar.image("https://www.ey.com/content/dam/ey-unified-site/ey-com/en-gr/insights/cybersecurity/images/ey-cybersecurity-eygreece-study-2023.png", use_container_width=True)
st.sidebar.title("üîç Navegaci√≥n")
section = st.sidebar.radio("Selecciona una secci√≥n", [
    "üè† Inicio", "üöÄ Ejecutar Data Pipeline", "üìä Visualizaci√≥n del Dataset y Gr√°ficos", "ü§ñ Ejecutar el Modelo"
])

# Secci√≥n 1: Inicio
if section == "üè† Inicio":
    st.title("Aplicaci√≥n de IA con Streamlit")
    st.write("Bienvenidos a nuestra aplicaci√≥n web dedicada a la detecci√≥n de intrusiones cibern√©ticas. Esta plataforma interactiva se ha desarrollado como parte de un proyecto acad√©mico con el objetivo de demostrar la integraci√≥n y automatizaci√≥n completa de un Data Pipeline junto con un modelo avanzado de inteligencia artificial.")
    if st.expander("üë• Mostrar Participantes del Proyecto"):
        st.markdown("""
        **Participantes del Proyecto:**  
        - üë®‚Äçüíª Nathan Ghenassia (Cientifico de Datos) 
        - üë©‚Äçüíª Maria Fernanda Camacho (Programadora Web)  
        - üë®‚Äçüíª Samuel Salazar (Ingeniero de Datos)  
        """)
    st.image("https://journal.ahima.org/Portals/0/EasyDNNnews/2633/img-Federal-cybersecurity-image-iStock-1420039900.jpg", caption="Esperamos que les guste!", use_container_width=True)

# Crear instancia del pipeline de datos
pipeline = DataPipeline(
    dataset_name="dnkumars/cybersecurity-intrusion-detection-dataset",
    github_user="NathanGhenassia",
    github_repo="Data_pipeline_and_ml",
    github_branch="main"
)

# Funci√≥n para obtener datasets desde GitHub en formato CSV
def load_dataset_from_github(filename):
    url = f"https://raw.githubusercontent.com/NathanGhenassia/Data_pipeline_and_ml/main/datos/{filename}"
    response = requests.get(url)
    if response.status_code == 200:
        return pd.read_csv(StringIO(response.text))
    else:
        st.error(f"No se pudo cargar el dataset {filename} desde GitHub.")
        return None

# Secci√≥n 2: Ejecutar Data Pipeline
if section == "üöÄ Ejecutar Data Pipeline":
    st.header("üöÄ Ejecutar Data Pipeline")
    st.write("Este c√≥digo implementa un pipeline de datos automatizado que permite la descarga, limpieza, encriptaci√≥n y carga de conjuntos de datos, integrando herramientas como KaggleApi y GitHub. Durante su ejecuci√≥n, el sistema genera logs detallados que documentan cada paso del proceso, desde la autenticaci√≥n en Kaggle y la eliminaci√≥n de valores NaN, hasta la encriptaci√≥n de datos sensibles y la subida de archivos procesados a GitHub, lo cual facilita la supervisi√≥n y el diagn√≥stico en caso de errores.")
    st.write("En este sitio web, hemos implementado una funci√≥n interactiva para demostrar la eficacia y funcionalidad de nuestro Data Pipeline. Al presionar el bot√≥n, podr√°s visualizar los logos que representan cada componente del Data Pipeline en acci√≥n.")
    if st.button("Ejecutar Data Pipeline"):
        with st.spinner("Ejecutando Data Pipeline..."):
            logs = pipeline.run_pipeline()
        st.success("‚úÖ Pipeline ejecutado exitosamente!")
        st.text_area("üìú Logs del pipeline", logs, height=300)
    st.image("https://miro.medium.com/v2/resize:fit:1400/1*RoFb2sFULMV-gnOy727FoQ.png", use_container_width=True)

# Secci√≥n 3: Visualizaci√≥n del Dataset y Gr√°ficos
if section == "üìä Visualizaci√≥n del Dataset y Gr√°ficos":
    st.header("üìä Visualizaci√≥n del Dataset y Gr√°ficos")
    df_original = load_dataset_from_github("dataset_original.csv")
    df_procesado = load_dataset_from_github("dataset_procesado.csv")

    if df_original is not None:
        st.subheader("üìå Dataset Original Encryptado")

        st.dataframe(df_original)
    
    if df_procesado is not None:
        st.subheader("üìà Gr√°ficos del Modelo")
        graphs_path = "outputs"

        # Explicaci√≥n y visualizaci√≥n del Histograma
        st.subheader("Histograma de distribuci√≥n de ataques detectados")
        st.write("La visualizaci√≥n muestra la distribuci√≥n de la variable attack_detected, que es la variable predictoria utilizada para identificar si se detect√≥ un ataque durante una sesi√≥n. Existen dos categor√≠as: 0, que indica la ausencia de un ataque, y 1, que representa la detecci√≥n de un ataque. Seg√∫n la gr√°fica de barras, la frecuencia de sesiones sin ataque (categor√≠a 0) es ligeramente mayor, con aproximadamente 4000 casos, en comparaci√≥n con las sesiones con ataque (categor√≠a 1), que rondan los 3500 casos. Este equilibrio relativo entre ambas clases hace que el dataset sea adecuado para entrenar modelos de detecci√≥n de intrusiones, permitiendo identificar patrones tanto de sesiones seguras como de aquellas comprometidas.")
        st.image("outputs/predict_variable_distribution.png")
        
        # Explicaci√≥n y visualizaci√≥n del Gr√°fico de Pastel
        st.subheader("Distribuci√≥n de variantes de protocolo")
        st.write("El gr√°fico de pastel muestra la distribuci√≥n de variantes de protocolo en el conjunto de datos. Se observa que el protocolo TCP es el m√°s utilizado, representando el 69.5% del total. Le sigue UDP con un 25.2%, mientras que ICMP tiene la menor participaci√≥n, con solo un 5.3%. Esto indica que la mayor√≠a del tr√°fico en el conjunto de datos se basa en conexiones orientadas a la transmisi√≥n confiable (TCP), mientras que UDP, que es m√°s r√°pido pero menos confiable, tiene una presencia menor. El protocolo ICMP, utilizado principalmente para diagn√≥sticos de red y mensajes de error, representa la menor proporci√≥n del tr√°fico.")
        st.image("outputs/protocol_pie_chart.png")
        
        # Explicaci√≥n y visualizaci√≥n del Mapa de Calor de Correlaci√≥n
        st.subheader("Mapa de calor de correlaci√≥n entre variables")
        st.write("La matriz de correlaci√≥n muestra la relaci√≥n entre diferentes variables del conjunto de datos. Se observa que la variable attack_detected tiene una correlaci√≥n positiva moderada con failed_logins (0.37) y login_attempts (0.28), lo que indica que un mayor n√∫mero de intentos de inicio de sesi√≥n o fallos en el acceso pueden estar asociados con la detecci√≥n de un ataque. Tambi√©n existe una correlaci√≥n positiva entre attack_detected y ip_reputation_score (0.21), lo que sugiere que direcciones IP con mala reputaci√≥n pueden estar relacionadas con ataques detectados. En contraste, otras variables como protocol_type, session_duration y browser_type tienen correlaciones m√°s d√©biles con attack_detected, lo que indica que su impacto en la detecci√≥n de ataques es menor.")
        st.image("outputs/variable_heatmap.png")

# Secci√≥n 4: Ejecutar el Modelo
if section == "ü§ñ Ejecutar el Modelo":
    st.header("ü§ñ Ejecutar el Modelo con el Dataset Procesado")
    st.write("Aqu√≠ podr√°s ver los resultados del modelo en tiempo real. En la secci√≥n de Predicciones, encontrar√°s las categor√≠as o valores estimados seg√∫n los datos ingresados. Justo debajo, se muestra la precisi√≥n del modelo (accuracy), que indica qu√© tan bien est√° funcionando la IA en t√©rminos de predicciones correctas. Adem√°s, podr√°s analizar la matriz de confusi√≥n, una herramienta visual que permite identificar los aciertos y errores del modelo en cada clase, ayudando a comprender mejor su desempe√±o.")

    def load_model():
        if os.path.exists("best_model.pkl"):
            return joblib.load("best_model.pkl")
        return None

    def load_scaler():
        if os.path.exists("scaler.pkl"):
            return joblib.load("scaler.pkl")
        return None

    if st.button("Ejecutar Modelo"):
        model = load_model()
        scaler = load_scaler()
        df_procesado = load_dataset_from_github("dataset_procesado.csv")
        
        if model and scaler and df_procesado is not None:
            st.subheader("üìå Predicciones del Modelo")
            X = df_procesado.drop(columns=['attack_detected'])
            y_true = df_procesado['attack_detected']
            X_scaled = scaler.transform(X)
            predictions = model.predict(X_scaled)
            df_procesado["Predicci√≥n"] = predictions
            st.dataframe(df_procesado)
            
            accuracy = accuracy_score(y_true, predictions)
            st.subheader("üéØ Precisi√≥n del Modelo")
            st.write(f"Precisi√≥n: {accuracy:.2%}")
            
            st.subheader("üìä Matriz de Confusi√≥n")
            cm = confusion_matrix(y_true, predictions)
            plt.figure(figsize=(6, 4))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                        xticklabels=["No Ataque", "Ataque"], 
                        yticklabels=["No Ataque", "Ataque"])
            plt.xlabel("Predicci√≥n")
            plt.ylabel("Real")
            st.pyplot(plt)
        else:
            st.error("‚ö†Ô∏è No se pudo ejecutar el modelo. Verifica que 'best_model.pkl' y 'scaler.pkl' est√©n disponibles.")
